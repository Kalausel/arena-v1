{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcca9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from typing import Optional, Callable\n",
    "import ipywidgets as wg\n",
    "from fancy_einsum import einsum\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "import torch\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bb8d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1805.29\n",
      "loss = 1231.80\n",
      "loss = 847.42\n",
      "loss = 589.77\n",
      "loss = 417.07\n",
      "loss = 301.30\n",
      "loss = 223.69\n",
      "loss = 171.66\n",
      "loss = 136.77\n",
      "loss = 113.38\n",
      "loss = 97.70\n",
      "loss = 87.18\n",
      "loss = 80.12\n",
      "loss = 75.39\n",
      "loss = 72.21\n",
      "loss = 70.08\n",
      "loss = 68.65\n",
      "loss = 67.68\n",
      "loss = 67.04\n",
      "loss = 66.60\n",
      "loss = 66.31\n",
      "loss = 66.11\n",
      "loss = 65.98\n",
      "loss = 65.89\n",
      "loss = 65.83\n",
      "loss = 65.79\n",
      "loss = 65.76\n",
      "loss = 65.74\n",
      "loss = 65.73\n",
      "loss = 65.72\n",
      "loss = 65.71\n",
      "loss = 65.71\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c709d88c7d4b41b0af35829ea7164a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = torch.stack([torch.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.stack([torch.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "a_0 = torch.rand(1, requires_grad=True)\n",
    "A_n = torch.rand(NUM_FREQUENCIES, requires_grad=True)\n",
    "B_n = torch.rand(NUM_FREQUENCIES, requires_grad=True)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "    \n",
    "    for coeff in [a_0, A_n, B_n]:\n",
    "        coeff.grad = None\n",
    "\n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = a_0/2 + torch.matmul(torch.transpose(x_cos, 0, 1), A_n) + torch.matmul(torch.transpose(x_sin, 0, 1), B_n)\n",
    "\n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = torch.square((y - y_pred)).sum()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0.item(), A_n.detach().tolist(), B_n.detach().tolist()])\n",
    "        y_pred_list.append(y_pred.tolist())\n",
    "\n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    loss.backward()\n",
    "\n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    with torch.no_grad():\n",
    "        for coeff in [a_0, A_n, B_n]:\n",
    "            coeff -= coeff.grad * LEARNING_RATE\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954b60b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.35\n",
      "loss = 0.29\n",
      "loss = 0.24\n",
      "loss = 0.21\n",
      "loss = 0.17\n",
      "loss = 0.15\n",
      "loss = 0.13\n",
      "loss = 0.11\n",
      "loss = 0.10\n",
      "loss = 0.08\n",
      "loss = 0.08\n",
      "loss = 0.07\n",
      "loss = 0.06\n",
      "loss = 0.06\n",
      "loss = 0.05\n",
      "loss = 0.05\n",
      "loss = 0.05\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42507fb8747b4162bf78e64e614a0949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1.0 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(2 * NUM_FREQUENCIES, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [x_cos, x_sin] of torch.Size(4, 2000)\n",
    "        # output is a 1-d tensor of length 2000\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "model = Model()\n",
    "loss_fct = nn.MSELoss()\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=torch.float32)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = torch.stack([torch.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.stack([torch.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_cos_sin = torch.swapaxes(torch.cat((x_cos, x_sin)), 0, 1)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = model(x_cos_sin)\n",
    "\n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = loss_fct(y_pred, y.unsqueeze(dim=1))\n",
    "    if step == 0:\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            if idx == 0:\n",
    "                A_n = param[0, 0:2].detach().tolist()\n",
    "                B_n = param[0, 2:4].detach().tolist()\n",
    "            elif idx == 1:\n",
    "                a_0 = 2 * param.detach().item()\n",
    "            else:\n",
    "                print(f\"Uncaught index {idx}\")\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0, A_n, B_n])\n",
    "        y_pred_list.append(y_pred.squeeze(dim=1).tolist())\n",
    "\n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= param.grad * LEARNING_RATE\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e43bbc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.43\n",
      "loss = 0.35\n",
      "loss = 0.29\n",
      "loss = 0.24\n",
      "loss = 0.20\n",
      "loss = 0.17\n",
      "loss = 0.14\n",
      "loss = 0.12\n",
      "loss = 0.10\n",
      "loss = 0.09\n",
      "loss = 0.08\n",
      "loss = 0.07\n",
      "loss = 0.06\n",
      "loss = 0.06\n",
      "loss = 0.05\n",
      "loss = 0.05\n",
      "loss = 0.05\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.04\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n",
      "loss = 0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baee599157034d2885c978e48c4325bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1.0 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(2 * NUM_FREQUENCIES, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [x_cos, x_sin] of torch.Size(4, 2000)\n",
    "        # output is a 1-d tensor of length 2000\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "model = Model()\n",
    "loss_fct = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=torch.float32)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = torch.stack([torch.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.stack([torch.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_cos_sin = torch.swapaxes(torch.cat((x_cos, x_sin)), 0, 1)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = model(x_cos_sin)\n",
    "\n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = loss_fct(y_pred, y.unsqueeze(dim=1))\n",
    "    if step == 0:\n",
    "        for idx, param in enumerate(model.parameters()):\n",
    "            if idx == 0:\n",
    "                A_n = param[0, 0:2].detach().tolist()\n",
    "                B_n = param[0, 2:4].detach().tolist()\n",
    "            elif idx == 1:\n",
    "                a_0 = 2 * param.detach().item()\n",
    "            else:\n",
    "                print(f\"Uncaught index {idx}\")\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0, A_n, B_n])\n",
    "        y_pred_list.append(y_pred.squeeze(dim=1).tolist())\n",
    "\n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    with torch.no_grad():\n",
    "        optimizer.step()\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
